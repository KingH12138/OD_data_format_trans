{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 关于目标检测常用数据集那些事"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from xml.dom.minidom import parse,Document\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 一.概述\n",
    "\n",
    "在深度学习任务中，检测任务可谓是最令人头疼的，其中一个原因便是其数据集复杂的数据结构，对于图像级别的目标检测，常见的便有voc、coco两种格式，对于视频级别的目标检测（时空动作检测模型），常见的为ava数据集格式。本文以voc、coco数据集之间的相互转化为主，剖析如何完成这些数据集格式之间的转换。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 二.几种格式的介绍\n",
    "\n",
    "### 1.两种位置信息表示方式\n",
    "\n",
    "首先需要明确，在2D检测任务中，如果想要标记一个物体就两种信息：**位置信息和类别信息**。其中，类别信息一般用**标记物体类别在classes_list(类别列表)中的下标**来表示。位置信息有两种表示方法：\n",
    "- xyxy:\n",
    "  $$\n",
    "  (x_{min},y_{min},x_{max},y_{max})\n",
    "  $$\n",
    "- xywh:\n",
    "  $$\n",
    "  (x_{center},y_{center},w,h)\n",
    "  $$\n",
    "\n",
    "### 2.txt存储格式(包含buffer格式)\n",
    "![图 2](images/d13b802d06319c89215a677ecba8db98c6dd1e6255dba000136465fb1387636c.png)  \n",
    "\n",
    "\n",
    "现在，我们才来介绍一种非常“原始”的存储方式——yolo txt，顾名思义就是使用txt文件存储标签信息（包含了：类别下标、位置信息）。一般来说：存储格式要求如下：\n",
    "\n",
    "- 每一行代表一个被标记的物体；\n",
    "- 一行有5个数据，从左往右依次为：类别信息，四个位置信息\n",
    "- 其中：类别信息最好**数字化**(转为下标形式)，位置信息需要**归一化**。\n",
    "\n",
    "当然，yolo txt也可以在内存中表示，比如说使用python中的list数据表示为：\n",
    "$$\n",
    "[label\\quad index,location\\quad data]\n",
    "$$\n",
    "\n",
    "这种buffer中的格式，我们也经常称之为：**bbox数据格式**。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.voc和xml\n",
    "\n",
    "\n",
    "#### (1)voc概述\n",
    "\n",
    "然后，我们来介绍一种现在使用可以说非常广泛的数据格式——VOC，全称为：Pascal Voc，至于它怎么产生和历史渊源咱们就不过多了解，重点了解其数据结构和组织形式。\n",
    "\n",
    "对于刚刚接触目标检测的好homie一般都是先了解到VOC的，从官网上下载voc2007后，其文件结构为：\n",
    "\n",
    "    └── VOCdevkit   #根目录\n",
    "        └── VOC2007 #除了2007版本还有2012版本等\n",
    "            ├── Annotations #存放xml文件，与JPEGImages中的图片对应，里面是标注物体信息以及图片信息等\n",
    "            ├── ImageSets   #存放txt文件\n",
    "            │   ├── Layout # 验证集和训练集的txt标记\n",
    "            │   ├── Main # 不同类别物体的标记\n",
    "            │   └── Segmentation # 验证集和训练集的txt标记\n",
    "            ├── JPEGImages         #存放的是原生图片\n",
    "            ├── SegmentationClass  #语义分割图片\n",
    "            └── SegmentationObject #实例分割图片\n",
    "\n",
    "其实没必要弄得很很复杂，对于今天我们搞定目标检测数据格式来说，我们只需要了解JPEGImages和Annotations足以。所以，一般来说你可以直接按照如下格式存储你自己标注的数据：\n",
    "\n",
    "![图 1](images/15943038400967a71cbc22857b06df6b27f946e911757b406a27dcb33d1f910f.png)  \n",
    "\n",
    "其中，JPEGImages存放你的数据集照片：\n",
    "\n",
    "![图 2](images/29057aa29d70beca22d960d7d1aecd17a15fc1a2ce5289f6edfa748acd33004e.png)  \n",
    "\n",
    "\n",
    "Annotations存放每张照片对应的信息文件(xml)：\n",
    "\n",
    "![图 3](images/6c73d837f3373e90d194b5ecb780048e52d08243c9aec8852f31fb92502ef845.png)  \n",
    "(可以看到xml文件和jpg图片文件是一一对应的(文件名字前缀一样))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "那么这个xml文件是什么呢？如果学过多媒体或者web的同学，老师应该会给你们讲：像一些网站需要中小型的数据库来**存储一些数据**的时候，可以使用xml文件来代替，这是xml的一大功能，另外一个功能便是存储网页或者软件的**用户配置信息**。\n",
    "\n",
    "#### (2)xml介绍\n",
    "\n",
    "说白了，xml跟html、css、txt等文件一样，本质上都是存储数据的，只不过存储格式不一样、编码格式不一样以此来适应不同的使用场合罢了——那么xml的存储格式不同在哪儿呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "html和xml是不是听起来很相似？没错，它俩可以说是一对兄弟，都是**树形结构**，有父、子、兄弟节点的，eg：\n",
    "\n",
    "![图 4](images/93fefc2064e2ef97002908e4fb39d72a2e0581e500fbe97ccbf8aa2b64b64725.png)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到上图中，annotation是最大的节点，其次是有folder、filename等兄弟节点。那么我们想要的信息就存储在：object和size以及filename中。因此，如何把voc格式数据也就是xml文件转化为txt格式，关键就在如何把这三个信息读取出来。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.coco格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图 1](images/4c9e3f515a2e5b6b843730ff14201d042737a8cfdcc981e159a7cfabcb614283.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "coco相较于voc数据集，共同点是都是可以运用在多个深度学习任务（目标检测、实例分割、语义分割等）中的数据集，其不同点：最为明显的就是COCO数据集所包含的种类数和图片数目更多。我们来看一下coco数据集的存放格式：\n",
    "\n",
    "    ├─annotations_trainval2014\n",
    "    │  └─annotations\n",
    "    └─train2014\n",
    "        └─train2014\n",
    "其中train2014存放的就是原生图片，annotations下存放的有三种深度学习任务的对应的train和val标注信息文件。（6个）我们可以来看一下,这些json文件长什么样子：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['info', 'images', 'licenses', 'annotations', 'categories'])\n",
      "{'description': 'COCO 2014 Dataset', 'url': 'http://cocodataset.org', 'version': '1.0', 'year': 2014, 'contributor': 'COCO Consortium', 'date_created': '2017/09/01'}\n",
      "[{'url': 'http://creativecommons.org/licenses/by-nc-sa/2.0/', 'id': 1, 'name': 'Attribution-NonCommercial-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nc/2.0/', 'id': 2, 'name': 'Attribution-NonCommercial License'}, {'url': 'http://creativecommons.org/licenses/by-nc-nd/2.0/', 'id': 3, 'name': 'Attribution-NonCommercial-NoDerivs License'}, {'url': 'http://creativecommons.org/licenses/by/2.0/', 'id': 4, 'name': 'Attribution License'}, {'url': 'http://creativecommons.org/licenses/by-sa/2.0/', 'id': 5, 'name': 'Attribution-ShareAlike License'}, {'url': 'http://creativecommons.org/licenses/by-nd/2.0/', 'id': 6, 'name': 'Attribution-NoDerivs License'}, {'url': 'http://flickr.com/commons/usage/', 'id': 7, 'name': 'No known copyright restrictions'}, {'url': 'http://www.usa.gov/copyright.shtml', 'id': 8, 'name': 'United States Government Work'}]\n"
     ]
    }
   ],
   "source": [
    "test_path = r'F:\\coco\\annotations_trainval2014\\annotations\\instances_val2014.json'\n",
    "file = open(test_path,'r')\n",
    "obj = json.load(file)\n",
    "print(type(obj))\n",
    "print(obj.keys())\n",
    "print(obj['info'])\n",
    "print(obj['licenses'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看到一个大字典，最重要的key就images、annotations、categories三种。一个大字典，下分3个主要key，其value均为list类型，三种key的每个list元素一一对应，元素又为一个小字典。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40504\n",
      "<class 'list'>\n",
      "{'license': 3, 'file_name': 'COCO_val2014_000000391895.jpg', 'coco_url': 'http://images.cocodataset.org/val2014/COCO_val2014_000000391895.jpg', 'height': 360, 'width': 640, 'date_captured': '2013-11-14 11:18:45', 'flickr_url': 'http://farm9.staticflickr.com/8186/8119368305_4e622c8349_z.jpg', 'id': 391895}\n"
     ]
    }
   ],
   "source": [
    "print(len(obj['images']))\n",
    "print(type(obj['images']))\n",
    "print(obj['images'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "images类中存放图片的下载url（我们自己写可以替换为自己存放的路径，或者直接不写），高、宽、文件名等主要信息，当然还一个最重要的——ID，我们自己写转换函数为了方便，可以直接用filename数字前缀作为ID。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "<class 'list'>\n",
      "{'supercategory': 'person', 'id': 1, 'name': 'person'}\n"
     ]
    }
   ],
   "source": [
    "print(len(obj['categories']))\n",
    "print(type(obj['categories']))\n",
    "print(obj['categories'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "哎，这儿有个很有意思的地方——这些类别不仅仅有**超类别**，还有子类别——估计是受到YOLOv2的wordtree启发？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291875\n",
      "<class 'list'>\n",
      "{'segmentation': [[239.97, 260.24, 222.04, 270.49, 199.84, 253.41, 213.5, 227.79, 259.62, 200.46, 274.13, 202.17, 277.55, 210.71, 249.37, 253.41, 237.41, 264.51, 242.54, 261.95, 228.87, 271.34]], 'area': 2765.1486500000005, 'iscrowd': 0, 'image_id': 558840, 'bbox': [199.84, 200.46, 77.71, 70.88], 'category_id': 58, 'id': 156}\n"
     ]
    }
   ],
   "source": [
    "print(len(obj['annotations']))\n",
    "print(type(obj['annotations']))\n",
    "print(obj['annotations'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "标注的话，可以看到有分割标注，但我们需要的是image_id和bbox标注，更重要的——可以看到291875>>40504，再加上这里只有一个bbox info，说明是一个标注物体为一个list元素。\n",
    "\n",
    "另外，这里的位置信息表示方式还值得商榷，我目前估计大可能不是xyxy。经过查阅资料得知，bbox从左往右为左上角x坐标、左上角y坐标、宽度、长度。但是我们自己写完全可以和其他几个格式统一起来，或者按照自己所需。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 三.转换实例"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "考虑到大家一般先接触到voc，同时coco和voc以及txt是外存上的数据，bbox是内存或者buffer中的数据，那么我们就以bbox作为**中心媒介数据格式**完成这三种数据集格式转换。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.voc -> bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readvocxml(xml_path, image_dir):\n",
    "    \"\"\"\n",
    "\n",
    "    The function can read single xml file and transform information of xml file into a list containing:\n",
    "    the filename of the xml indicates(str),\n",
    "    the filepath of image that xml indicates(a str.you need to give the dir which this image located in.Aka,the second parameter.)\n",
    "    the depth,height,width of the Image(three int data.channel first),\n",
    "    the annotated objects' infomation.(\n",
    "        a 2D int list:\n",
    "        [\n",
    "            row1:[label_1,xmin_1,ymin_1,xmax_1,ymax_1]\n",
    "            row2:[label_2,xmin_2,ymin_2,xmax_2,ymax_2]\n",
    "            ....\n",
    "            row_i[label_i,xmin_i,ymin_i,xmax_i,ymax_i]\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    Args:\n",
    "\n",
    "    xml_path:singal xml file's path.\n",
    "\n",
    "    image_dir:the image's location dir that xml file indicates.\n",
    "    (不加这个参数的话，就算不用我写的代码，都可能会出些很恶心的小bug，建议和JPEGImages联立起来)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    tree = parse(xml_path)\n",
    "    rootnode = tree.documentElement\n",
    "    sizenode = rootnode.getElementsByTagName('size')[0]\n",
    "    width = int(sizenode.getElementsByTagName('width')[0].childNodes[0].data)\n",
    "    height = int(sizenode.getElementsByTagName('height')[0].childNodes[0].data)\n",
    "    depth = int(sizenode.getElementsByTagName('depth')[0].childNodes[0].data)\n",
    "\n",
    "    name_node = rootnode.getElementsByTagName('filename')[0]\n",
    "    filename = name_node.childNodes[0].data\n",
    "\n",
    "    path = image_dir + '\\\\' + filename\n",
    "\n",
    "    objects = rootnode.getElementsByTagName('object')\n",
    "    objects_info = []\n",
    "    for object in objects:\n",
    "        label = object.getElementsByTagName('name')[0].childNodes[0].data\n",
    "        xmin = int(object.getElementsByTagName('xmin')[0].childNodes[0].data)\n",
    "        ymin = int(object.getElementsByTagName('ymin')[0].childNodes[0].data)\n",
    "        xmax = int(object.getElementsByTagName('xmax')[0].childNodes[0].data)\n",
    "        ymax = int(object.getElementsByTagName('ymax')[0].childNodes[0].data)\n",
    "        info = []\n",
    "        info.append(label)\n",
    "        info.append(xmin)\n",
    "        info.append(ymin)\n",
    "        info.append(xmax)\n",
    "        info.append(ymax)\n",
    "        objects_info.append(info)\n",
    "\n",
    "    return [filename, path, depth, height, width, objects_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000005.jpg', 'D:\\\\PythonCode\\\\OD_dataset_format\\\\voc\\\\JPEGImages\\\\000005.jpg', 3, 375, 500, [['chair', 263, 211, 324, 339], ['chair', 165, 264, 253, 372], ['chair', 5, 244, 67, 374], ['chair', 241, 194, 295, 299], ['chair', 277, 186, 312, 220]]]\n"
     ]
    }
   ],
   "source": [
    "objects_info = readvocxml(xml_path=r'./voc/Annotations/000005.xml',image_dir=r'D:\\PythonCode\\OD_dataset_format\\voc\\JPEGImages')\n",
    "print(objects_info) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说，这里的readxml已经足够应付普通的目标检测了，但一般我自己为了应付使用DIF的情况并使得各个数据之间的转换更加方便，会多读取几个参数，反正根据自己所需改代码吧。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.bbox -> txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2txt(objects_info,filename,save_dir):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        objects_info:（已经是归一化和标签数字化的2D列表）\n",
    "        a 2D int list:\n",
    "            [\n",
    "                row1:[label_1,xmin_1,ymin_1,xmax_1,ymax_1]\n",
    "                row2:[label_2,xmin_2,ymin_2,xmax_2,ymax_2]\n",
    "                ....\n",
    "                row_i[label_i,xmin_i,ymin_i,xmax_i,ymax_i]\n",
    "            ]\n",
    "        filename:the txt filename.（txt前缀）\n",
    "        save_dir:the directory you want to save txt file.\n",
    "    \"\"\"\n",
    "    with open(\"{}/{}.txt\".format(save_dir,filename),'w') as f:\n",
    "        lines = \"\"\n",
    "        for object_ in objects_info:\n",
    "            line = \"{} {} {} {} {}\\n\".format(\n",
    "                object_[0],\n",
    "                object_[1],\n",
    "                object_[2],\n",
    "                object_[3],\n",
    "                object_[4]\n",
    "            )\n",
    "            lines = lines + line\n",
    "        f.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:00<00:00, 208.86it/s]\n"
     ]
    }
   ],
   "source": [
    "# 批量转换\n",
    "ann_dir = r'D:\\PythonCode\\OD_dataset_format\\voc\\Annotations'\n",
    "txt_save_dir = r'D:\\PythonCode\\OD_dataset_format\\txt'\n",
    "txt_path=r'D:\\PythonCode\\OD_dataset_format\\voc\\classes.txt'\n",
    "for ann_name in tqdm(os.listdir(ann_dir)):\n",
    "    ann_path = ann_dir + '/' + ann_name \n",
    "    filename, path, depth, height, width, objects_info = readvocxml(ann_path,txt_path)   # voc -> bbox\n",
    "    filename = filename.split('.')[0]\n",
    "    bbox2txt(objects_info,filename,txt_save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图 5](images/8c6967044ed1fcd4374ddc2897378af1d7692b9cb62a3cf92d7a665e4677df3e.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.txt -> bbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txt2bbox(txt_path):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        txt_path:单个txt路径\n",
    "    Returns:\n",
    "        objects_info:与txt存储方式一样的2D列表\n",
    "        filename:文件名前缀\n",
    "    \"\"\"\n",
    "    objects_info = []\n",
    "    sig = 0 # 0:filename前是/,  1:filename前是\\\\\n",
    "    for i in range(1,len(txt_path)+1):\n",
    "        if txt_path[-i]=='\\\\':\n",
    "            sig=1\n",
    "            break\n",
    "        if txt_path[-i]=='/':\n",
    "            break\n",
    "    if sig:\n",
    "        filename = txt_path.split('\\\\')[-1].split('.')[0]\n",
    "    else:\n",
    "        filename = txt_path.split('/')[-1].split('.')[0]\n",
    "\n",
    "    with open(txt_path,'r') as f:\n",
    "        info_list = f.read().split('\\n')[:-1]\n",
    "        info_list = [i.split() for i in info_list]\n",
    " \n",
    "        for info in info_list:\n",
    "            info_ = []\n",
    "            info_.append(info[0])\n",
    "            info_.append(int(info[1]))    # 位置信息: str->float\n",
    "            info_.append(int(info[2]))\n",
    "            info_.append(int(info[3]))\n",
    "            info_.append(int(info[4]))\n",
    "            objects_info.append(info_) \n",
    "    return objects_info,filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['chair', 263, 211, 324, 339], ['chair', 165, 264, 253, 372], ['chair', 5, 244, 67, 374], ['chair', 241, 194, 295, 299], ['chair', 277, 186, 312, 220]] 000005\n"
     ]
    }
   ],
   "source": [
    "objects_info,filename = txt2bbox(r\"D:\\PythonCode\\OD_dataset_format\\txt\\000005.txt\")\n",
    "print(objects_info, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.bbox -> xml\n",
    "\n",
    "这里要稍微麻烦一些，我们需要了解如何写一个”xml树“。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图 6](images/3cad3e6ef0a4ac864b97556f2de06d8e78654e22380c709cafedab92a774f0ac.png)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了简化使用，我们只取上图中框出来的信息，其他参数可以根据自己所需加入。(可能存在多个object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2xml(objects_info, img_filename, image_shape, save_dir):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        objects_info:归一化的、标签数字化的2D列表\n",
    "        img_filename:xml对应图片文件名\n",
    "        image_shape:为了方便使用者自定义，需要手动输入\n",
    "        classes_path:classes txt存储路径\n",
    "        save_dir:xml保存目录\n",
    "    \"\"\"\n",
    "    d,h,w = image_shape\n",
    "    doc = Document()\n",
    "    # 文件根节点\n",
    "    annotation = doc.createElement('annotation')\n",
    "    doc.appendChild(annotation)\n",
    "    # 建立四个仅次于文件根节点的兄弟节点\n",
    "    filename_node = doc.createElement('filename')\n",
    "    annotation.appendChild(filename_node)\n",
    "    filename_ = doc.createTextNode(img_filename)\n",
    "    filename_node.appendChild(filename_)\n",
    "    size_node = doc.createElement('size')\n",
    "    annotation.appendChild(size_node)    \n",
    "    # size节点下分三个节点:width,height,depth\n",
    "    w_node = doc.createElement('width')\n",
    "    h_node = doc.createElement('height')\n",
    "    d_node = doc.createElement('depth')\n",
    "    size_node.appendChild(w_node)\n",
    "    size_node.appendChild(h_node)\n",
    "    size_node.appendChild(d_node)\n",
    "    w_ = doc.createTextNode(str(w))\n",
    "    h_ = doc.createTextNode(str(h))\n",
    "    d_ = doc.createTextNode(str(d))\n",
    "    w_node.appendChild(w_)\n",
    "    h_node.appendChild(h_)\n",
    "    d_node.appendChild(d_)\n",
    "    \n",
    "    for i in range(len(objects_info)):\n",
    "        object_ = objects_info[i]\n",
    "        name,xmin,ymin,xmax,ymax = object_\n",
    "        object_node = doc.createElement('object')\n",
    "        annotation.appendChild(object_node)\n",
    "        # object下分两个节点：name和bndbox\n",
    "        name_node = doc.createElement('name')\n",
    "        object_node.appendChild(name_node)\n",
    "        name_ = doc.createTextNode(name)\n",
    "        name_node.appendChild(name_)\n",
    "        # 位置信息结点建立\n",
    "        bnd_node = doc.createElement('bndbox')\n",
    "        object_node.appendChild(bnd_node)\n",
    "        xmin_node = doc.createElement('xmin')\n",
    "        ymin_node = doc.createElement('ymin')\n",
    "        xmax_node = doc.createElement('xmax')\n",
    "        ymax_node = doc.createElement('ymax')\n",
    "        bnd_node.appendChild(xmin_node)\n",
    "        bnd_node.appendChild(ymin_node)\n",
    "        bnd_node.appendChild(xmax_node)\n",
    "        bnd_node.appendChild(ymax_node)\n",
    "        xmin_ = doc.createTextNode(str(xmin))\n",
    "        ymin_ = doc.createTextNode(str(ymin))\n",
    "        xmax_ = doc.createTextNode(str(xmax))\n",
    "        ymax_ = doc.createTextNode(str(ymax))\n",
    "        xmin_node.appendChild(xmin_)\n",
    "        ymin_node.appendChild(ymin_)\n",
    "        xmax_node.appendChild(xmax_)\n",
    "        ymax_node.appendChild(ymax_)\n",
    "    \n",
    "    # 写入文件\n",
    "    with open(save_dir+'/'+img_filename.split('.')[0]+'.xml','w') as f:\n",
    "        f.write(doc.toprettyxml(indent=\"    \"))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_info,filename = txt2bbox(r\"D:\\PythonCode\\OD_dataset_format\\txt\\000005.txt\")\n",
    "bbox2xml(objects_info,filename+'.jpg',(3,375,500), './')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图 7](images/b3e97dee7ed8835684ad85589aae00f07ccef1a69fde849a9e5ffdd2d0b34eec.png)  \n",
    "\n",
    "对比一下，发现没有问题，说明功能实现成功。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.voc -> coco\n",
    "\n",
    "这里为什么不直接bbox转为coco，是因为，coco格式数据集其实是整体的——一整个数据集标注就用一个json文件存储，而且最重要的是图片与标注关联度很强，那么直接读入bbox来写不太容易，传入参数太多。\n",
    "\n",
    "此数据转换的难点在于如何写入json文件，其实很简单，前面已经演示了，python可以将json文件解析为自己的字典类型。还记得刚刚讲的三个主要keys吗？\n",
    "\n",
    "- images:图片名字、路径、c、h、w、id(可选，直接写成数字前缀也行)；\n",
    "- annotations:bbox信息、对应图片id；\n",
    "- categories:类别id、类别名字；\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def voc2coco(jpg_dir,ann_dir,txt_path,json_path):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            jpg_dir:JPEGimage路径\n",
    "            ann_dir:Annotations路径\n",
    "            txt_path:classes.txt路径\n",
    "            json_path:存储的json文件路径\n",
    "    \"\"\"\n",
    "    obj = {'images':[],'annotations':[],'categories':[]}\n",
    "    # 先把种类搞定\n",
    "    with open(txt_path,'r') as f:\n",
    "        cls_list = f.read().split('\\n')[:-1]\n",
    "    for i in range(len(cls_list)):\n",
    "        cate_dict = {}\n",
    "        cate_dict['id']=i   # clslist下标作为cate_id\n",
    "        cate_dict['name']=cls_list[i]   \n",
    "        obj['categories'].append(cate_dict)\n",
    "    # 搞定images和annotations\n",
    "    for filename in tqdm(os.listdir(ann_dir)):\n",
    "        img_dict = {}\n",
    "        xml_path = ann_dir + '/' + filename\n",
    "        filename, path, depth, height, width, objects_info = readvocxml(xml_path,jpg_dir)\n",
    "        # img_dict\n",
    "        img_dict['filename']=filename\n",
    "        img_dict['id']=filename.split('.')[0]   # filename前缀作为id\n",
    "        img_dict['depth']=depth\n",
    "        img_dict['height']=height\n",
    "        img_dict['width']=width\n",
    "        img_dict['path']=path\n",
    "        obj['images'].append(img_dict)\n",
    "        # ann_duct\n",
    "        for object_ in objects_info:\n",
    "            ann_dict = {}\n",
    "            ann_dict['bbox']=object_[1:]\n",
    "            ann_dict['category_id']=object_[0]\n",
    "            ann_dict['image_id']=filename.split('.')[0]\n",
    "            obj['annotations'].append(ann_dict)\n",
    "    # 最后写入json文件\n",
    "    with open(json_path,'w') as fb:\n",
    "        json.dump(obj,fb,indent=\"   \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:00<00:00, 1683.38it/s]\n"
     ]
    }
   ],
   "source": [
    "voc2coco(\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\voc\\JPEGImages',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\voc\\Annotations',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\voc\\classes.txt',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\coco\\annotation_train\\voc2007tococo.json'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.coco -> voc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco2voc(src_dir,json_path,ann_dir,txt_path):\n",
    "    \"\"\"\n",
    "        Args:\n",
    "            src_dir:coco图片目录\n",
    "            json_path:coco标注json文件路径\n",
    "            ann_dir:voc的Annotations目录\n",
    "            txt_path:为voc生成的classes.txt路径\n",
    "    \"\"\"\n",
    "    with open(json_path,'r') as f:\n",
    "        obj = json.load(f)\n",
    "        ann_info = obj['annotations']\n",
    "        cls_info = obj['categories']\n",
    "        # 先生成classes.txt:\n",
    "        id_cate = {}\n",
    "        for item in cls_info:\n",
    "            id_cate[int(item['id'])]=item['name']\n",
    "        cls_list = [0 for i in range(len(id_cate))]\n",
    "        for key in id_cate.keys():\n",
    "            cls_list[key]=id_cate[key]  # 要保证id从小到大输出\n",
    "        content = \"\"\n",
    "        for cls in cls_list:\n",
    "            content = content + cls + '\\n'\n",
    "        with open(txt_path,'w') as f:\n",
    "            f.write(content)        \n",
    "        # 建立图片-标注物体字典并完成转换\n",
    "        img_obj_dict = {}\n",
    "        for item in ann_info:\n",
    "            img_obj_dict[item['image_id']]=[]\n",
    "        for item in ann_info:\n",
    "            img_obj_dict[item['image_id']].append([item['category_id']]+item['bbox'])\n",
    "        for key in tqdm(img_obj_dict.keys()):\n",
    "        ######################  tips:默认图片格式为jpg，如果不是要改一下下方{}后的\".jpg\"  ###################### \n",
    "            img_path = src_dir + '/' + \"{}.jpg\".format(key)\n",
    "            shape = cv2.imread(img_path).shape\n",
    "            objects_info = img_obj_dict[key]\n",
    "            bbox2xml(objects_info,key+'.jpg',(shape[-1],shape[0],shape[1]),ann_dir)\n",
    "        ######################################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 197/197 [00:01<00:00, 105.21it/s]\n"
     ]
    }
   ],
   "source": [
    "coco2voc(\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\coco\\train2014',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\coco\\annotation_train\\voc2007tococo.json',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\voc(coco-trans)\\Annotations',\n",
    "    r'D:\\PythonCode\\OD_dataset_format\\voc(coco-trans)\\classes.txt'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 四.总结\n",
    "\n",
    "![图 1](images/ec4219ebba8a84a237df80029727c99e1c3e35754f9c36ec4477617ec11069e0.png)  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('torch18')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "027911db67f240fc9f5e47b0a1e00176e48824f79107a86bfe9900f81692c748"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
